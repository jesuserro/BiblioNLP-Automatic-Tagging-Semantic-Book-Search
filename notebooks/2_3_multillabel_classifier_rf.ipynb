{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77e410351fa406e8eab8cbcfc401f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "Mejores hiperparámetros: {'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__n_estimators': 10}\n",
      "Mejor puntuación (CV): 0.20174340187586454\n",
      "Puntuación final en test: 0.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../model/book_tagging_rf_mlb.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# 1) Cargar datos\n",
    "books_df = pd.read_csv(\"../data/raw/goodreads_data.csv\")\n",
    "\n",
    "# Combinar stopwords de nltk con otras posibles palabras irrelevantes\n",
    "my_stop_words = {'to-read', 'closed', 'abandoned-books'\n",
    "'rating-top', 'literature', 'not-interested', 'libricos', 'recommended',\n",
    "'000-next', \n",
    "'001-ladder-top', '002-ladder-short-term', '003-ladder-medium-term', '004-ladder-long-term', \n",
    "'005-ladder-maybe-someday', \n",
    "'_cristina', '_giorgia', '_natalia', '_nieves', '_pilar', '_sindy', '_víctor', 'chełmińska'\n",
    "}\n",
    "stop_words = set(my_stop_words)\n",
    "stop_words = stop_words.union(set(stopwords.words('english')))\n",
    "stop_words = stop_words.union(set(stopwords.words('spanish')))\n",
    "stop_words = stop_words.union(set(stopwords.words('french')))\n",
    "stop_words = stop_words.union(set(stopwords.words('italian')))\n",
    "\n",
    "# 3. Procesar los tags: convertirlos en listas y filtrar stop-words\n",
    "def filter_stopwords(tags):\n",
    "    \"\"\"\n",
    "    Filtra las stop-words de una lista de etiquetas.\n",
    "    \"\"\"\n",
    "    return [tag for tag in tags if tag.lower() not in stop_words]\n",
    "\n",
    "\n",
    "books_df.rename(columns={\n",
    "    \"Book\": \"book_title\",\n",
    "    \"Description\": \"blurb\",\n",
    "    \"Genres\": \"tags\"\n",
    "}, inplace=True)\n",
    "\n",
    "books_df[\"tags\"] = books_df[\"tags\"].fillna(\"[]\").apply(\n",
    "    lambda x: \", \".join(\n",
    "        tag.strip().lower().replace(\" \", \"-\") for tag in eval(x)\n",
    "    )\n",
    ")\n",
    "\n",
    "books_df = books_df.sample(1000, random_state=42)\n",
    "\n",
    "books_df[\"book_title\"] = books_df[\"book_title\"].fillna(\"\")\n",
    "books_df[\"blurb\"] = books_df[\"blurb\"].fillna(\"\")\n",
    "books_df[\"tags\"] = books_df[\"tags\"].fillna(\"\")\n",
    "books_df[\"text\"] = books_df[\"book_title\"] + \". \" + books_df[\"blurb\"]\n",
    "\n",
    "\n",
    "# Filtyer stopwords from text\n",
    "books_df['tags'] = books_df['tags'].apply(lambda x: filter_stopwords([t.strip() for t in str(x).split(',')]))\n",
    "books_df['text'] = books_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))\n",
    "\n",
    "# 7) Cargar Sentence-BERT y vectorizar\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2') \n",
    "X = model.encode(books_df['text'].tolist(), show_progress_bar=True)\n",
    "\n",
    "# 8) Binarizar las etiquetas\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(books_df['tags'])\n",
    "\n",
    "# 9) Separar train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 10) Construir el Random Forest en modo multi-output\n",
    "rf_base = RandomForestClassifier(random_state=42)\n",
    "multi_rf = MultiOutputClassifier(rf_base)\n",
    "\n",
    "# 11) Definir la grilla de hiperparámetros\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [50, 100, 200],  # Incrementar el número de árboles\n",
    "    'estimator__max_depth': [10, 20, None],     # Probar con mayor profundidad\n",
    "    'estimator__min_samples_leaf': [1, 2, 5],   # Ajustar el tamaño mínimo de hojas\n",
    "    'estimator__class_weight': ['balanced']     # Balancear clases automáticamente\n",
    "}\n",
    "\n",
    "# 2) Cambiar la métrica de evaluación\n",
    "grid_search = GridSearchCV(\n",
    "    multi_rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # Incrementar el número de folds\n",
    "    scoring='f1_macro',  # Cambiar a f1_macro para multietiqueta\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación (CV):\", grid_search.best_score_)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# 13) Evaluar en test\n",
    "test_score = best_rf.score(X_test, y_test)\n",
    "print(\"Puntuación final en test:\", test_score)\n",
    "\n",
    "# 14) Guardar modelo y binarizador\n",
    "joblib.dump(best_rf, \"../model/book_tagging_rf.joblib\")\n",
    "joblib.dump(mlb, \"../model/book_tagging_rf_mlb.joblib\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
